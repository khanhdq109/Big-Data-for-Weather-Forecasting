{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","\n","import findspark\n","findspark.init()\n","findspark.find() \n","\n","import pyspark.pandas as ps\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler, IndexToString\n","from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, MultilayerPerceptronClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DATASET_PATH = 'datasets/historical-hourly-weather-dataset/'\n","AGGREGATED_DATASET_PATH = 'datasets/historical-hourly-weather-dataset/aggregated_sampled_weather_measurements'"]},{"cell_type":"markdown","metadata":{},"source":["# Data pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Machine Learning pipeline"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get all the csv files in the aggregated dataset folder\n","csv_files = [file for file in os.listdir(AGGREGATED_DATASET_PATH) if file.endswith('.csv')]\n","\n","# Read each CSV file into a Koalas DataFrame and store them in a list\n","dfs = [ps.read_csv(os.path.join(AGGREGATED_DATASET_PATH, file)) for file in csv_files]\n","\n","# Combine the DataFrames using the concat function\n","data = ps.concat(dfs, ignore_index = True)"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-processing"]},{"cell_type":"markdown","metadata":{},"source":["Select relevant features and label column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Select relevant features\n","numerical_cols = [\n","    'humidity',\n","    'pressure',\n","    'temperature',\n","    'wind_direction',\n","    'wind_speed',\n","    'latitude',\n","    'longitude'\n","]\n","nominal_cols = []\n","# Select the label column\n","label_col = 'weather_condition'\n","# Select the features and the label\n","df_selected = data[numerical_cols + nominal_cols + [label_col]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_selected.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert the Koalas DataFrame to a Spark DataFrame\n","df_selected = df_selected.to_spark()"]},{"cell_type":"markdown","metadata":{},"source":["Train-Test split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data, test_data = df_selected.randomSplit([0.8, 0.2], seed = 42)"]},{"cell_type":"markdown","metadata":{},"source":["Encode"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def encode(\n","    df,\n","    numerical_cols = [],\n","    nominal_cols = [],\n","    label_col = '',\n","    with_std = True,\n","    with_mean = True,\n","):\n","    # Convert categorical label to numerical label\n","    label_indexer = StringIndexer(\n","        inputCol = label_col,\n","        outputCol = 'label',\n","        handleInvalid = 'keep'\n","    )\n","    \n","    # Assemble features into a vector\n","    feature_cols = numerical_cols + nominal_cols\n","    vector_assembler = VectorAssembler(\n","        inputCols = feature_cols,\n","        outputCol = 'raw_features'\n","    )\n","    \n","    # Scale the features\n","    scaler = StandardScaler(\n","        inputCol = 'raw_features',\n","        outputCol = 'scaled_features',\n","        withStd = with_std,\n","        withMean = with_mean\n","    )\n","    \n","    stages = [label_indexer, vector_assembler, scaler]\n","    pipeline = Pipeline(stages = stages)\n","    \n","    transformer = pipeline.fit(df)\n","    \n","    return transformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_encoder = encode(\n","    df = df_selected,\n","    numerical_cols = numerical_cols,\n","    nominal_cols = nominal_cols,\n","    label_col = label_col\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Start training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate(predictions):\n","    accuracy = MulticlassClassificationEvaluator(\n","        labelCol = 'label',\n","        predictionCol = 'prediction',\n","        metricName = 'accuracy'\n","    )\n","    precision = MulticlassClassificationEvaluator(\n","        labelCol = 'label',\n","        predictionCol = 'prediction',\n","        metricName = 'weightedPrecision'\n","    )\n","    recall = MulticlassClassificationEvaluator(\n","        labelCol = 'label',\n","        predictionCol = 'prediction',\n","        metricName = 'weightedRecall'\n","    )\n","    f1 = MulticlassClassificationEvaluator(\n","        labelCol = 'label',\n","        predictionCol = 'prediction',\n","        metricName = 'f1'\n","    )\n","    \n","    print('Accuracy:', accuracy.evaluate(predictions))\n","    print('Precision:', precision.evaluate(predictions))\n","    print('Recall:', recall.evaluate(predictions))\n","    print('F1:', f1.evaluate(predictions))"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = RandomForestClassifier(\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n","    numTrees = 15\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Predict and evaluate on test data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["### Logistic Regression"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = LogisticRegression(\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Predict and evaluate on test data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy = evaluate(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = DecisionTreeClassifier(\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Predict and evaluate on test data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy = evaluate(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["### Multilayer Perceptron"]},{"cell_type":"markdown","metadata":{},"source":["Define the layers of the neural network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["layers = [len(numerical_cols) + len(nominal_cols), 32, 64, 128, 6]"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = MultilayerPerceptronClassifier(\n","    layers = layers,\n","    blockSize = 128,\n","    seed = 42,\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n","    maxIter = 500\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Predict and evaluate on test data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy = evaluate(predictions)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"Weather_forecasting_pyspark","notebookOrigID":1252952709241176,"widgets":{}},"kernelspec":{"display_name":"weather","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
