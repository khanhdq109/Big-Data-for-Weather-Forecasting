{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Found pyspark version \"3.5.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n","WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"]}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","\n","import findspark\n","findspark.init()\n","findspark.find() \n","\n","import databricks.koalas as ks\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n","from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, MultilayerPerceptronClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["DATASET_PATH = 'datasets/historical-hourly-weather-dataset/'\n","AGGREGATED_DATASET_PATH = 'datasets/historical-hourly-weather-dataset/aggregated_sampled_weather_measurements'"]},{"cell_type":"markdown","metadata":{},"source":["# Machine Learning pipeline"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Get all the csv files in the aggregated dataset folder\n","csv_files = [file for file in os.listdir(AGGREGATED_DATASET_PATH) if file.endswith('.csv')]\n","\n","# Read each CSV file into a Koalas DataFrame and store them in a list\n","dfs = [ks.read_csv(os.path.join(AGGREGATED_DATASET_PATH, file)) for file in csv_files]\n","\n","# Combine the DataFrames using the concat function\n","data = ks.concat(dfs, ignore_index = True)"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-processing"]},{"cell_type":"markdown","metadata":{},"source":["Select relevant features and label column"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Select relevant features\n","numerical_cols = [\n","    'humidity',\n","    'pressure',\n","    'temperature',\n","    'wind_direction',\n","    'wind_speed',\n","    'latitude',\n","    'longitude'\n","]\n","nominal_cols = []\n","# Select the label column\n","label_col = 'weather_condition'\n","# Select the features and the label\n","df_selected = data[numerical_cols + [label_col]]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["spark = SparkSession.builder.getOrCreate()\n","df_selected = df_selected.to_spark()"]},{"cell_type":"markdown","metadata":{},"source":["Train-Test split"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_data, test_data = df_selected.randomSplit([0.8, 0.2], seed = 42)"]},{"cell_type":"markdown","metadata":{},"source":["Encode"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def encode(\n","    df,\n","    numerical_cols = [],\n","    nominal_cols = [],\n","    label_col = '',\n","    with_std = True,\n","    with_mean = True,\n","):\n","    # Convert categorical label to numerical label\n","    label_indexer = StringIndexer(\n","        inputCol = label_col,\n","        outputCol = 'label',\n","        handleInvalid = 'keep'\n","    )\n","    \n","    # Assemble features into a vector\n","    feature_cols = numerical_cols + nominal_cols\n","    vector_assembler = VectorAssembler(\n","        inputCols = feature_cols,\n","        outputCol = 'raw_features'\n","    )\n","    \n","    # Scale the features\n","    scaler = StandardScaler(\n","        inputCol = 'raw_features',\n","        outputCol = 'scaled_features',\n","        withStd = with_std,\n","        withMean = with_mean\n","    )\n","    \n","    stages = [label_indexer, vector_assembler, scaler]\n","    pipeline = Pipeline(stages = stages)\n","    \n","    transformer = pipeline.fit(df)\n","    \n","    return transformer\n","\n","data_encoder = encode(\n","    df = df_selected,\n","    numerical_cols = numerical_cols,\n","    nominal_cols = nominal_cols,\n","    label_col = label_col\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Start training"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["classifier = RandomForestClassifier(\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n","    numTrees = 30\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Make predictions on the test data"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate the model performance"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5201468836840016\n"]}],"source":["accuracy = evaluator.evaluate(predictions)\n","print('Accuracy:', accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["### Logistic Regression"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["classifier = LogisticRegression(\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/11/10 21:47:03 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"]}],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Make predictions on the test data"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate the model performance"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.48947995236204844\n"]}],"source":["accuracy = evaluator.evaluate(predictions)\n","print('Accuracy:', accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["classifier = DecisionTreeClassifier(\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Make predictions on the test data"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate the model performance"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.508634378721715\n"]}],"source":["accuracy = evaluator.evaluate(predictions)\n","print('Accuracy:', accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["### Multilayer Perceptron"]},{"cell_type":"markdown","metadata":{},"source":["Define the layers of the neural network"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["layers = [len(numerical_cols) + len(nominal_cols), 32, 64, 128, 6]"]},{"cell_type":"markdown","metadata":{},"source":["Define the classifier"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["classifier = MultilayerPerceptronClassifier(\n","    layers = layers,\n","    blockSize = 128,\n","    seed = 42,\n","    featuresCol = 'scaled_features',\n","    labelCol = 'label',\n","    maxIter = 500\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define the pipeline with the encoding and classifier stages"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages = [data_encoder, classifier])"]},{"cell_type":"markdown","metadata":{},"source":["Define the evaluator"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol = 'label',\n","    predictionCol = 'prediction',\n","    metricName = 'accuracy'\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Define hyperparameter tuning (optional)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# Define the grid of hyperparameters\n","param_grid = ParamGridBuilder().build()\n","\n","# Set up the cross validator for model training and hyperparameter tuning\n","cross_validator = CrossValidator(\n","    estimator = pipeline,\n","    estimatorParamMaps = param_grid,\n","    evaluator = evaluator,\n","    numFolds = 5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Fit the model using the training data"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["model = cross_validator.fit(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Make predictions on the test data"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate the model performance"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.556570067487098\n"]}],"source":["accuracy = evaluator.evaluate(predictions)\n","print('Accuracy:', accuracy)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"Weather_forecasting_pyspark","notebookOrigID":1252952709241176,"widgets":{}},"kernelspec":{"display_name":"weather","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
